{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "53e07fce-b637-4a68-b80e-b8e8d9264eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "42950d9a-79a5-4bcb-bf49-c88444d0e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (300, 300)\n",
    "BATCH_SIZE = 8\n",
    "NUM_CLASSES = 10\n",
    "CLASS_NAMES = [\"traffic light\", \"traffic sign\", \"car\", \"person\", \"bike\", \"bus\", \"truck\", \"rider\", \"train\", \"motor\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4a979a9-9456-4fa5-a8fd-0531caf5b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUGMENTATION = A.Compose([A.Resize(height=IMG_SIZE[0], width=IMG_SIZE[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1d8962-cb8d-4595-9db6-8c1656c3fc5d",
   "metadata": {},
   "source": [
    "load the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be553f2e-9119-482b-8639-012703a9f803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(label_file):\n",
    "    \"\"\"\n",
    "    This function loads the labels and returns the labels\n",
    "\n",
    "    Args:\n",
    "    label_file = File path of the json file.\n",
    "\n",
    "    Returns:\n",
    "    It returns the loaded labels\n",
    "    \"\"\"\n",
    "    with open(file=label_file, mode='r') as f:\n",
    "        return json.load(fp=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b7e5cf-e77b-45b2-96e8-66e0ea30fd3b",
   "metadata": {},
   "source": [
    "preprocess image pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e1b6de-20ea-4d50-97b0-89a3555a879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_image(image_path):\n",
    "    \"\"\"\n",
    "    This function read the image and converts to RGB format\n",
    "\n",
    "    Args:\n",
    "    image_path: Training image file path.\n",
    "\n",
    "    Returns:\n",
    "    It returns coloe corrected image.\n",
    "    \"\"\"\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7393326-8b7d-4c4d-84be-d7cb3f7b21c3",
   "metadata": {},
   "source": [
    "preprocess a sample pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5010e146-2c15-4595-b657-a5d5cc660af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample(sample, image_dir):\n",
    "    \"\"\"\n",
    "    This function returns processed image, bounding box coordinates and label associated with the image.\n",
    "\n",
    "    Args:\n",
    "    Sample: Sample image from the training dataset.\n",
    "    image_dir: Training image path.\n",
    "\n",
    "    Return:\n",
    "    It processed image, bounding box coordinates and label associated with the image.\n",
    "    \"\"\"\n",
    "    image_path = os.path.join(image_dir, sample['name'])\n",
    "    image = preprocessing_image(image_path=image_path)\n",
    "    \n",
    "    #place holders for the bounding boxes dimensions and labels\n",
    "    b_boxes = []\n",
    "    labels = []\n",
    "\n",
    "    #extarct bounding box dimensions and labels from sample\n",
    "    for item in sample['labels']:\n",
    "        if \"box2d\" in item:\n",
    "            x1, y1, x2, y2 = item['box2d']['x1'], item['box2d']['y1'], item['box2d']['x2'], item['box2d']['y2']\n",
    "            b_boxes.append([x1, y1, x2, y2])\n",
    "            labels.append(item['category'])\n",
    "\n",
    "    #resize the image\n",
    "    augmented = AUGMENTATION(image=image, bboxes=b_boxes)\n",
    "\n",
    "    return augmented['image'], np.array(b_boxes), np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5fd6e6-e40e-4be0-aac9-7117d4db7cec",
   "metadata": {},
   "source": [
    "image genarator pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1ab9f362-9a1d-4643-9e60-fc0b1b696876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(image_dir, label_file, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    This function generate batches of images, bounding boxes & labels\n",
    "\n",
    "    Args:\n",
    "    image_dir: Image path\n",
    "    label_file: class labels\n",
    "    batch_size: Training image batch size\n",
    "\n",
    "    Return:\n",
    "    It yields the batches of images, bounding boxes & labels\n",
    "\n",
    "    \"\"\"\n",
    "    labels_data = load_labels(label_file)\n",
    "    total_images = len(labels_data)\n",
    "\n",
    "    while True:\n",
    "        for i in range(0, total_images, batch_size):\n",
    "            batch_images = labels_data[i:i + batch_size]\n",
    "            images, boxes, labels = [], [], []\n",
    "            max_objects = 10\n",
    "\n",
    "            for sample in batch_images:\n",
    "                img, box, lbl = process_sample(sample, image_dir)\n",
    "                images.append(img)\n",
    "                boxes.append(box[:max_objects])\n",
    "                labels.append([CLASS_NAMES.index(l) for l in lbl[:max_objects]])\n",
    "            \n",
    "            #Convert to TensorFlow Ragged Tensors to handle varying sizes\n",
    "            images = np.array(images)  # (batch, 300, 300, 3)\n",
    "            boxes_padded = np.zeros((len(boxes), max_objects, 4))  # Fixed size (batch, 10, 4)\n",
    "            for j in range(len(boxes)):\n",
    "                boxes_padded[j, :len(boxes[j])] = boxes[j]\n",
    "            padded_labels = np.zeros((len(labels), max_objects), dtype=np.int32)  # Pad with `0`\n",
    "            for j in range(len(labels)):\n",
    "                padded_labels[j, :len(labels[j])] = labels[j]\n",
    "                \n",
    "\n",
    "            labels_onehot = to_categorical(padded_labels, num_classes=NUM_CLASSES)  # One-hot encode\n",
    "\n",
    "            # Flatten `labels_onehot` to match model shape `(batch, 10 * NUM_CLASSES)`\n",
    "            labels_onehot = labels_onehot.reshape(len(labels), -1)\n",
    "\n",
    "            \n",
    "            yield images, {\"bounding_box\": boxes_padded.reshape(len(boxes), -1), \"class_label\": labels_onehot}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8bead3-ca75-4c92-9659-9b4382b55b49",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "87806bc1-2d63-4ebd-a391-d3462bdc4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data and file paths\n",
    "IMAGE_DIR = \"D:/learning_desk/bosch_assignment_bdd_100k/data/bdd100k/images/train\"\n",
    "LABEL_FILE = 'D:/learning_desk/bosch_assignment_bdd_100k/data/bdd100k/labels/bdd100k_labels_images_train.json'\n",
    "#train_data = data_generator(IMAGE_DIR, LABEL_FILE, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e3aae50e-698e-4364-8920-0622fc3bd0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Batch Shapes:\n",
      "  Images: (8, 300, 300, 3)\n",
      "  Bounding Boxes: (8, 33, 4)\n",
      "  Labels (One-Hot): (8, 33, 10)\n"
     ]
    }
   ],
   "source": [
    "sample_batch = next(train_data)\n",
    "images_batch, labels_batch = sample_batch\n",
    "\n",
    "print(\"Sample Batch Shapes:\")\n",
    "print(f\"  Images: {images_batch.shape}\")\n",
    "print(f\"  Bounding Boxes: {labels_batch['bounding_box'].shape}\")\n",
    "print(f\"  Labels (One-Hot): {labels_batch['class_label'].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "ae522add-dbf1-4b33-ac7c-7fef1238c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_generator(\n",
    "    lambda: data_generator(IMAGE_DIR, LABEL_FILE, batch_size=BATCH_SIZE),\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(None, 300, 300, 3), dtype=tf.float32),  # Images\n",
    "        {\n",
    "            \"bounding_box\": tf.TensorSpec(shape=(None, 40), dtype=tf.float32),  # (10 objects * 4 coords)\n",
    "            \"class_label\": tf.TensorSpec(shape=(None, 10 * NUM_CLASSES), dtype=tf.float32),  # (10 objects * classes)\n",
    "        }\n",
    "    )\n",
    ").prefetch(tf.data.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "bd843b52-3b48-474e-84b3-4972a80266af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 300, 300, 3), dtype=tf.float32, name=None), {'bounding_box': TensorSpec(shape=(None, 40), dtype=tf.float32, name=None), 'class_label': TensorSpec(shape=(None, 100), dtype=tf.float32, name=None)})>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3777f9fc-4b88-48a4-b5a5-91ae4e74babf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (300, 300, 3)\n",
      "Bounding Boxes: (7, 4)\n",
      "Labels: (7,)\n"
     ]
    }
   ],
   "source": [
    "labels_data = load_labels(LABEL_FILE)\n",
    "\n",
    "# Test one sample\n",
    "sample = labels_data[0]\n",
    "image, b_boxes, labels = process_sample(sample, IMAGE_DIR)\n",
    "\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Bounding Boxes:\", b_boxes.shape)\n",
    "print(\"Labels:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd389319-e01e-4d38-9f14-99fd6729ea6d",
   "metadata": {},
   "source": [
    "model build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6ab64525-1873-48ed-9db1-050e14b8a1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"\n",
    "    This funtion Builds a multi-task model for object detection + classification and returns the model.\n",
    "    \n",
    "    Args:\n",
    "\n",
    "    Returns:\n",
    "    It returns a model\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Base Model\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=(300, 300, 3), include_top=False)\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Object Detection Branch\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x1 = tf.keras.layers.Dense(128, activation=\"relu\")(x1)\n",
    "    bbox_output = tf.keras.layers.Dense(40, activation=\"linear\", name=\"bounding_box\")(x1)  # Predicts (10 objects * 4)\n",
    "\n",
    "    # Classification Branch\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x2 = tf.keras.layers.Dense(128, activation=\"relu\")(x2)\n",
    "    class_output = tf.keras.layers.Dense(10 * NUM_CLASSES, activation=\"softmax\", name=\"class_label\")(x2)  # Predicts (10 objects * classes)\n",
    "\n",
    "    # Define Multi Output Model\n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=[bbox_output, class_output])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss={\"bounding_box\": \"mse\", \"class_label\": \"categorical_crossentropy\"},\n",
    "        metrics={\"bounding_box\": \"mae\", \"class_label\": \"accuracy\"},\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ba4bc173-bd79-4d89-a07c-3eb6b5ac1203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vijiv\\AppData\\Local\\Temp\\ipykernel_4396\\3900031214.py:5: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  base_model = tf.keras.applications.MobileNetV2(input_shape=(300, 300, 3), include_top=False)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "368046d3-40e5-4b33-ab3d-077dccecb498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/learning_desk/bosch_assignment_bdd_100k/models/ssd_mobilenet_v2_bdd.h5'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = 'D:/learning_desk/bosch_assignment_bdd_100k/models/'\n",
    "model_name = 'ssd_mobilenet_v2_bdd.h5'\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "e4c93409-792c-4e13-9426-bcf7a4d10c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 409ms/step - bounding_box_loss: 217071.1250 - bounding_box_mae: 387.9644 - class_label_accuracy: 1.2439e-04 - class_label_loss: 107.3109 - loss: 217178.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.fit(train_data, epochs=1, steps_per_epoch=100)\n",
    "model.save(filepath=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c7539-8eb4-4a5b-b5be-435264b98035",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bosch_env",
   "language": "python",
   "name": "bosch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
